
# ğŸ“š ì´ë¯¸ì§€ ë¶„ë¥˜(Image Classification) ëŒ€í‘œ ëª¨ë¸ ì´ì •ë¦¬

ì´ ë¬¸ì„œëŠ” ì´ë¯¸ì§€ ë¶„ë¥˜ì— ì‚¬ìš©ë˜ëŠ” ëŒ€í‘œì ì¸ ëª¨ë¸ë“¤ì˜ ë°œì „ íë¦„ê³¼ êµ¬ì¡°, ì„±ëŠ¥, ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ë“œ/ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ë³´ë¥¼ í¬í•¨í•œ ì •ë¦¬ì…ë‹ˆë‹¤.



## ğŸ§­ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ íƒ€ì„ë¼ì¸ ìš”ì•½

| ì‹œëŒ€ | ì£¼ìš” ëª¨ë¸ | ë¹„ê³  |
|------|-----------|------|
| 2012~2014 | AlexNet, VGG | CNNì˜ ë¶€í¥ê¸° |
| 2015~2017 | ResNet, Inception, DenseNet | ê¹Šì€ ë„¤íŠ¸ì›Œí¬ + skip ì—°ê²° |
| 2018~2020 | EfficientNet, RegNet | ìë™ êµ¬ì¡° íƒìƒ‰ (NAS) |
| 2021~í˜„ì¬ | ViT, Swin Transformer, ConvNeXt | Transformer ê¸°ë°˜ ë˜ëŠ” CNN-Transformer í•˜ì´ë¸Œë¦¬ë“œ |

---

## ğŸ“Š ëŒ€í‘œ ëª¨ë¸ ë¹„êµí‘œ

| ëª¨ë¸ëª… | ë°œí‘œì—°ë„ | êµ¬ì¡° íŠ¹ì§• | ì¥ì  | í•œê³„ | Params (M) | Top-1@ImageNet |
|--------|----------|------------|------|------|-------------|----------------|
| **AlexNet** | 2012 | 5 Conv + 3 FC | ReLU, GPU í•™ìŠµ ë„ì… | ê¹Šì´ ë¶€ì¡± | 60M | 57.0% |
| **VGG16** | 2014 | 3Ã—3 Conv ë°˜ë³µ | ë‹¨ìˆœí•œ êµ¬ì¡°, ì§ê´€ì  | íŒŒë¼ë¯¸í„° ë§ìŒ | 138M | 71.5% |
| **GoogLeNet (Inception v1)** | 2014 | Inception module | ê³„ì‚° íš¨ìœ¨ â†‘ | êµ¬ì¡° ë³µì¡ | 7M | 69.8% |
| **ResNet-50** | 2015 | Residual block | ê¹Šì€ ë„¤íŠ¸ì›Œí¬ ì•ˆì •í™” | ì—°ì‚°ëŸ‰ ë§ìŒ | 25M | 76.2% |
| **DenseNet-121** | 2017 | Dense connection | íŒŒë¼ë¯¸í„° íš¨ìœ¨ â†‘ | ë³‘ë ¬í™” ì–´ë ¤ì›€ | 8M | 75.0% |
| **EfficientNet-B0** | 2019 | Compound scaling | ë†’ì€ ì •í™•ë„, ì ì€ ì—°ì‚° | êµ¬ì¡° ìƒì„± ë³µì¡ | 5M | 77.1% |
| **RegNetY-16GF** | 2020 | êµ¬ì¡° íŒ¨í„´ ìˆ˜ì‹í™” | ìµœì í™” ìë™í™” | ì§ê´€ì„± ë‚®ìŒ | 84M | 80.9% |
| **ViT-B/16** | 2021 | Patch + Transformer | ì „ì—­ ì •ë³´ ì²˜ë¦¬ ê°•í•¨ | ë§ì€ ë°ì´í„° í•„ìš” | 86M | 77.9% |
| **DeiT-B** | 2021 | ViT + Distillation | ì†ŒëŸ‰ ë°ì´í„°ë„ í•™ìŠµ | ViTê¸‰ ì„±ëŠ¥ | 86M | 81.8% |
| **Swin-T** | 2021 | Shifted Windows | ì—°ì‚° íš¨ìœ¨, ê³„ì¸µ êµ¬ì¡° | êµ¬ì¡° ë‹¤ì†Œ ë³µì¡ | 29M | 81.3% |
| **ConvNeXt-T** | 2022 | ViT ìŠ¤íƒ€ì¼ CNN | ViT ì„±ëŠ¥ + CNN ì¹œí™”ì„± | ë‹¤ì†Œ ë¬´ê±°ì›€ | 29M | 82.1% |

---

## ğŸ”§ ëª¨ë¸ë³„ ì½”ë“œ ì‚¬ìš©ë²•

| ëª¨ë¸ | ë¼ì´ë¸ŒëŸ¬ë¦¬ | ì‚¬ìš© ë°©ë²• |
|------|------------|-----------|
| **AlexNet** | `torchvision` | `torchvision.models.alexnet(pretrained=True)` |
| **VGG16** | `torchvision` | `torchvision.models.vgg16(pretrained=True)` |
| **GoogLeNet** | `torchvision` | `torchvision.models.googlenet(pretrained=True)` |
| **ResNet-50** | `torchvision` | `torchvision.models.resnet50(pretrained=True)` |
| **DenseNet-121** | `torchvision` | `torchvision.models.densenet121(pretrained=True)` |
| **EfficientNet-B0** | `torchvision` | `torchvision.models.efficientnet_b0(pretrained=True)` |
| **RegNetY-16GF** | `torchvision` | `torchvision.models.regnet_y_16gf(pretrained=True)` |
| **ViT-B/16** | `transformers` by HuggingFace | `AutoModel.from_pretrained("google/vit-base-patch16-224")` |
| **DeiT-B** | `transformers` or `timm` | `timm.create_model("deit_base_patch16_224", pretrained=True)` |
| **Swin-T** | `timm` | `timm.create_model("swin_tiny_patch4_window7_224", pretrained=True)` |
| **ConvNeXt-T** | `timm` | `timm.create_model("convnext_tiny", pretrained=True)` |

---

## ğŸ” ì£¼ìš” ê°œë… ìš”ì•½

| ê°œë… | ì„¤ëª… |
|------|------|
| **Residual connection** | ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í•™ìŠµ ì•ˆì •í™” (ResNet) |
| **Inception module** | ë‹¤ì–‘í•œ ì»¤ë„ ë³‘ë ¬ ì‚¬ìš© (GoogLeNet) |
| **Dense connection** | ëª¨ë“  ë ˆì´ì–´ë¥¼ ì—°ê²° (DenseNet) |
| **Neural Architecture Search (NAS)** | êµ¬ì¡°ë¥¼ ìë™ íƒìƒ‰ (EfficientNet) |
| **Transformer** | ì „ì—­ attention ì‚¬ìš© (ViT, Swin) |
| **Window Attention** | êµ­ì†Œ attention + ì „ì—­ íë¦„ (Swin) |

---

## ğŸ”š ìš”ì•½ ì •ë¦¬

- **CNN ê³„ì—´**: VGG â†’ ResNet â†’ DenseNet â†’ EfficientNet
- **Transformer ê³„ì—´**: ViT â†’ Swin â†’ ConvNeXt
- **ì¶”ì„¸**: ViT ê³„ì—´ì´ ê¸‰ì„±ì¥ ì¤‘ì´ì§€ë§Œ, CNNë„ ê³„ì† ì§„í™” (ConvNeXt ë“±)

---



## âœ… ì°¸ê³ 

- PyTorch Docs: https://pytorch.org/vision/stable/models.html
- HuggingFace ViT: https://huggingface.co/google/vit-base-patch16-224
- Timm ëª¨ë¸ ë¦¬ìŠ¤íŠ¸: https://rwightman.github.io/pytorch-image-models/

