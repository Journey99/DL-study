# ğŸ“˜ Pre-requisite: Transformer ê¸°ë°˜ Object Detection ì´í•´ë¥¼ ìœ„í•œ ì‚¬ì „ ì§€ì‹

Transformer ê¸°ë°˜ ê°ì²´ íƒì§€ ëª¨ë¸(DETR, Deformable DETR, DAB-DETR, DINO ë“±)ì„ ì´í•´í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì•Œê³  ìˆì–´ì•¼ í•  ê¸°ë³¸ ê°œë…ë“¤ì„ ì •ë¦¬í•œ ê²ƒì´ë‹¤.


## 1. Transformer ê¸°ë³¸ êµ¬ì¡°
- **Self-Attention**  
  ì…ë ¥ featureë“¤ì´ ì„œë¡œ ê´€ê³„ë¥¼ ë§ºìœ¼ë©° global contextë¥¼ í•™ìŠµ.  
- **Encoderâ€“Decoder êµ¬ì¡°**  
  - Encoder: ì´ë¯¸ì§€ ì „ì²´ featureë¥¼ ì¸ì½”ë”©  
  - Decoder: Object Queryë¥¼ ì…ë ¥ë°›ì•„ ê°ì²´ ìœ„ì¹˜ì™€ í´ë˜ìŠ¤ë¥¼ ë””ì½”ë”©  
- **Position Embedding**  
  CNNê³¼ ë‹¬ë¦¬ ìˆœì„œ ì •ë³´ê°€ ì—†ê¸° ë•Œë¬¸ì— ìœ„ì¹˜ ì •ë³´ë¥¼ sine/cosine embeddingìœ¼ë¡œ ì¶”ê°€  



## 2. Object Query
- DETR ê³„ì—´ì˜ í•µì‹¬ ì•„ì´ë””ì–´  
- í•™ìŠµ ê°€ëŠ¥í•œ embedding (vector)ìœ¼ë¡œ, ë””ì½”ë”ì— ì…ë ¥ë¨  
- ë””ì½”ë”ëŠ” ê° queryë¥¼ ë°˜ë³µ ì—…ë°ì´íŠ¸í•˜ì—¬ **"ì–´ë–¤ ê°ì²´ê°€ ì–´ë””ì— ìˆëŠ”ì§€"**ë¥¼ ì˜ˆì¸¡  



## 3. Bipartite Matching (Hungarian Algorithm)
- ê¸°ì¡´ CNN ê¸°ë°˜ detectionì€ NMS(Non-Maximum Suppression) ì‚¬ìš©  
- DETRì€ **set prediction** ë°©ì‹ì„ ì±„íƒ  
- ì˜ˆì¸¡ ë°•ìŠ¤ì™€ GT ë°•ìŠ¤ë¥¼ **1:1 ë§¤ì¹­** â†’ ì¤‘ë³µ íƒì§€ ì œê±°, ë” ê¹”ë”í•œ í•™ìŠµ ê°€ëŠ¥  


## 4. Loss Functions
- **Classification Loss**: Cross-Entropy Loss (í´ë˜ìŠ¤ ë¶„ë¥˜)  
- **Localization Loss**: L1 Loss + GIoU/DIoU/CIoU Loss (ë°•ìŠ¤ ì¢Œí‘œ íšŒê·€)  
- **Set-based Loss**: Hungarian matchingìœ¼ë¡œ ë§¤ì¹­ëœ pairì—ë§Œ ì ìš©  


## 5. Multi-scale Feature Representation
- ê°ì²´ í¬ê¸° ë‹¤ì–‘ì„± ë¬¸ì œ í•´ê²°  
- **FPN (Feature Pyramid Network)**: CNN ê¸°ë°˜ multi-scale feature ì‚¬ìš©  
- **Deformable DETR**: multi-scale feature mapì—ì„œ ìƒ˜í”Œë§í•˜ì—¬ attention  


## 6. Deformable Attention
- Standard attentionì€ ëª¨ë“  í”½ì…€ì— ëŒ€í•´ attention â†’ ê³„ì‚°ëŸ‰ â†‘  
- Deformable Attentionì€ **ì¼ë¶€ ìƒ˜í”Œë§ í¬ì¸íŠ¸ë§Œ ì„ íƒì ìœ¼ë¡œ ì°¸ì¡°**  
- â†’ ì—°ì‚° íš¨ìœ¨ â†‘, ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì²˜ë¦¬ ê°€ëŠ¥  


## 7. Query Denoising
- í•™ìŠµ ì´ˆê¸°ì— ìˆ˜ë ´ ì†ë„ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë“±ì¥ (DN-DETR, DINO ë“±)  
- GT box/labelì— noiseë¥¼ ì¶”ê°€í•œ queryë¥¼ í•™ìŠµì‹œì¼œ ëª¨ë¸ì´ ë” ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµ  

## 8. Dynamic Anchor Box (DAB-DETR)
- ê¸°ì¡´ DETRì˜ object queryëŠ” ë‹¨ìˆœ vector  
- DAB-DETRì—ì„œëŠ” queryë¥¼ **ìœ„ì¹˜ ì •ë³´ê°€ í¬í•¨ëœ anchor í˜•íƒœ**ë¡œ ì´ˆê¸°í™”  
- í•™ìŠµ ì†ë„ì™€ ì•ˆì •ì„± ê°œì„   

## 9. Anchor-free Detection
- ê¸°ì¡´ (YOLO, SSD ë“±) â†’ Anchor Box ê¸°ë°˜ (ë¯¸ë¦¬ ì •ì˜ëœ ë°•ìŠ¤ì™€ ë§¤ì¹­)  
- DETR ê³„ì—´ â†’ **Anchor-free** â†’ ì¢Œí‘œë¥¼ ì§ì ‘ íšŒê·€í•˜ì—¬ ì˜ˆì¸¡  

## 10. Vision-Language í™•ì¥
- ìµœì‹  Transformer ê¸°ë°˜ ëª¨ë¸ë“¤ì€ í…ìŠ¤íŠ¸ì™€ ê²°í•©  
  - **Grounding-DINO**: í…ìŠ¤íŠ¸ ì¡°ê±´ ê¸°ë°˜ ê°ì²´ íƒì§€  
  - **GLIP**: Object detection + Text grounding í†µí•© í•™ìŠµ  

---

## âœ… ìš”ì•½
- **Transformer ê¸°ë³¸ê¸°**: attention, encoder-decoder, position embedding  
- **DETRì˜ í•µì‹¬**: object query, bipartite matching, set-based loss  
- **ì„±ëŠ¥ ê°œì„  ìš”ì†Œ**: multi-scale feature, deformable attention, query denoising, dynamic anchor  
- **ìµœì‹  ì¶”ì„¸**: Vision-Language ìœµí•©  

