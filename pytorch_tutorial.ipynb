{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 내용은 [공식 pytorch 튜토리얼](https://tutorials.pytorch.kr/beginner/basics/intro.html) 의 내용입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서(TENSOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 텐서 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로부터 직접 텐서 생성하기\n",
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "# numpy 배열로부터 생성하기\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "# 다른 텐서로부터 생성하기\n",
    "x_one = torch.ones_like(x_data) # x_data 속성 유지\n",
    "x_rand = torch.randn_like(x_data, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무작위 값을 사용하기\n",
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 텐서 속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "# tensor = torch.rand(3,4, device=\"mps\")\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    tensor = tensor.to(\"mps\")\n",
    "\n",
    "del tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 텐서 연결\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 산술 연산\n",
    "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산합니다. y1, y2, y3은 모두 같은 값을 갖습니다.\n",
    "# ``tensor.T`` 는 텐서의 전치(transpose)를 반환합니다.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "print(y1)\n",
    "\n",
    "# 요소별 곱(element-wise product)을 계산합니다. z1, z2, z3는 모두 같은 값을 갖습니다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Numpy 변환\n",
    "cpu 상의 텐서와 numpy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다르 하나도 변경된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET 과 DATALOADER\n",
    "- 가독성과 모듈성을 위해 데이터셋 코드를 모델 학습 코드로부터 분리\n",
    "- torch.utils.data.DataLoader 와 torch.utils.data.Dataset 을 제공\n",
    "  - Dataset은 샘플과 정답을 저장\n",
    "  - DataLoader는 Dataset을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체로 감싼다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 순회하고 시각화\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 사용자 정의 데이터셋 만들기 (Dataset class)\n",
    "- 사용자 정의 dataset 클래스는 반드시 3개 함수를 구현해야 함\n",
    "  - \\_\\_init\\_\\_ : 데이터셋의 크기를 반환, 이미지와 레이블이 포함된 디렉토리와 변형 작업을 초기화\n",
    "  - \\_\\_len\\_\\_ : 데이터 개수 반환\n",
    "  - \\_\\_getitem\\_\\_ : 데이터와 해당 레이블을 반환, idx를 기반으로 이미지의 위치를 식별하고 이미지를 텐서로 변환하고, 정답을 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'])\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) DataLoader로 학습용 데이터 준비하기\n",
    "- Dataset은 데이터의 특징을 가져오고 하나의 샘플에 정답을 지정하는 일을 한다\n",
    "- 모델을 학습할 때, 일반적으로 샘플들을 미니배치로 전달하고, 매 에폭마다 데이터를 다시 섞어서 과적합을 막고 python의 multiprocessing을 사용하여 데이터 검색 속도를 높인다\n",
    "- DataLoader는 간단한 api로 이러한 복잡한 과정들을 추상화한 순회 가능한 객체다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0039, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0118, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0078, 0.0275, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       " \n",
       " \n",
       "         [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]),\n",
       " tensor([5, 3, 0, 0, 0, 0, 8, 4, 4, 8, 2, 1, 1, 8, 3, 2, 4, 0, 5, 3, 5, 2, 1, 9,\n",
       "         7, 3, 5, 9, 5, 3, 1, 9, 8, 0, 4, 6, 5, 5, 0, 2, 4, 3, 7, 1, 6, 0, 7, 7,\n",
       "         3, 1, 2, 9, 2, 3, 7, 5, 4, 8, 2, 9, 0, 9, 0, 5]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "train_features, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변형(TRANSFORM)\n",
    "\n",
    "알고리즘 학습에 필요한 최종 처리가 된 형태로 데이터를 제공하려면 변형을 해서 데이터를 조작하고 학습에 적합하게 만든다\n",
    "\n",
    "모든 torchvision 데이터셋들은 변형 로직을 갖는, 호출 가능한 객체를 받는 매개변수 두개 (feature 변경을 위한 transform과 정답을 변경하기 위한 target_transform) 를 갖는다. torchvision.transforms 모듈은 주로 사용하는 몇가지 변형을 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "- 10개의 0.0으로 된 초기화된 텐서를 생성하고\n",
    "- 입력 값인 레이블 y를 텐서로 변환하고\n",
    "- scatter\\_ 메서드를 활용하여 'y'에 해당하는 인덱스에 1을 할당한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) ToTensor()\n",
    "ToTensor는 PIL Image나 Numpy ndarry를 floattensor로 변환하고, 이미지의 픽셀의 크기 값을 [0,1] 범위로 비례하여 조정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 모델 구성하기\n",
    "\n",
    "신경망은 데이터에 대한 연산을 수행하는 layer/module로 구성되어 있다. \n",
    "torch.nn 은 신경망을 구성하는데 필요한 모든 구성 요소를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) gpu 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 클래스 정의하기\n",
    "- 신경망 모델을 nn.Moudel의 하위클래스로 정의하고, \\_\\_init\\_\\_ 에서 신경망 계층들을 초기화한다\n",
    "- nn.Moudel을 상속받은 모든 클래스는 forward 메소드에 입력 데이터에 대한 연산들을 구현한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([4], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 모델 계층 (layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = torch.rand(3,28,28)\n",
    "input_img.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Flatten\n",
    "- 입력 텐서의 차원을 평탄화하는 역할을 한다\n",
    "- 여기서 평탄화는 텐서를 1차원으로 변환하는 과정!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_img = flatten(input_img)\n",
    "flat_img.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Linear\n",
    "- 저장된 가중치와 편향을 사용하여 입력에 선형 변환(linear transformation)을 적용하는 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_img)\n",
    "hidden1.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.ReLU\n",
    "- 비선형 활성화 함수는 모델의 입력과 출력 사이에 복잡한 관계를 만든다\n",
    "- 비선형 활성화 함수는 선형 변환 후에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.8560, -0.0950,  0.0296,  0.2517,  0.2331, -0.3400,  0.0875, -0.3510,\n",
      "          0.8025, -0.2412, -0.1415,  0.2394,  0.4563, -0.4510,  0.1886,  0.3413,\n",
      "         -0.7440, -0.5138, -0.3472,  0.4617],\n",
      "        [-0.8979, -0.0698,  0.0428,  0.8731,  0.4327,  0.3016,  0.0654, -0.1087,\n",
      "          0.5964, -0.4222, -0.3294,  0.0635, -0.0022, -0.4860,  0.3396,  0.5448,\n",
      "         -0.3581, -0.2814, -0.4462,  0.1208],\n",
      "        [-0.9047, -0.3617,  0.0607,  0.6165,  0.2501, -0.0665, -0.0371,  0.0100,\n",
      "          0.6476, -0.2865,  0.0118,  0.1672,  0.0562, -0.0747,  0.3563,  0.3800,\n",
      "         -0.7538, -0.5374, -0.4474,  0.2055]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.0296, 0.2517, 0.2331, 0.0000, 0.0875, 0.0000, 0.8025,\n",
      "         0.0000, 0.0000, 0.2394, 0.4563, 0.0000, 0.1886, 0.3413, 0.0000, 0.0000,\n",
      "         0.0000, 0.4617],\n",
      "        [0.0000, 0.0000, 0.0428, 0.8731, 0.4327, 0.3016, 0.0654, 0.0000, 0.5964,\n",
      "         0.0000, 0.0000, 0.0635, 0.0000, 0.0000, 0.3396, 0.5448, 0.0000, 0.0000,\n",
      "         0.0000, 0.1208],\n",
      "        [0.0000, 0.0000, 0.0607, 0.6165, 0.2501, 0.0000, 0.0000, 0.0100, 0.6476,\n",
      "         0.0000, 0.0118, 0.1672, 0.0562, 0.0000, 0.3563, 0.3800, 0.0000, 0.0000,\n",
      "         0.0000, 0.2055]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Sequential\n",
    "- 순서를 갖는 모듈의 컨테이너\n",
    "- 데이터는 정의된 것과 같은 순소러 모든 모듈들을 통해 전달된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1687,  0.1552, -0.4135,  0.0091, -0.0277, -0.1875,  0.0590, -0.0919,\n",
       "         -0.3001,  0.0010],\n",
       "        [-0.1737,  0.2153, -0.4720, -0.0129, -0.0205, -0.1971,  0.1355, -0.0758,\n",
       "         -0.2340,  0.1128],\n",
       "        [-0.1056,  0.1191, -0.3214,  0.0310, -0.0106, -0.1843,  0.2879,  0.0095,\n",
       "         -0.2633,  0.0959]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_moduels = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10)\n",
    ")\n",
    "\n",
    "input_img = torch.rand(3,28,28)\n",
    "logits = seq_moduels(input_img)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Softmax\n",
    "- 신경망의 마지막 선형 계층은 nn.Softmax 를 사용하여 모델의 각 분류에 대한 예측 확률을 [0,1] 범위로 나타내도록 조정\n",
    "- 매개변수는 값의 합이 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0918, 0.1270, 0.0719, 0.1097, 0.1057, 0.0901, 0.1153, 0.0992, 0.0805,\n",
       "         0.1088],\n",
       "        [0.0887, 0.1309, 0.0658, 0.1042, 0.1034, 0.0867, 0.1209, 0.0978, 0.0835,\n",
       "         0.1181],\n",
       "        [0.0917, 0.1148, 0.0739, 0.1051, 0.1008, 0.0847, 0.1359, 0.1028, 0.0783,\n",
       "         0.1121]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 모델 매개변수\n",
    "신경망 내부의 많은 계층들은 매개변수화 되는데 즉, 학습 중에 최적화되는 가중치와 편향과 연관지어진다. nn.Module을 상속하면 모델 객체 내부의 모든 필드들이 자동으로 추적되며 모델의 parameters() 및 named_parameters() 메소드로 모든 매개변수에 접근할 수 있게 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0334, -0.0251, -0.0023,  ...,  0.0218,  0.0250,  0.0108],\n",
      "        [-0.0131,  0.0087,  0.0158,  ...,  0.0008,  0.0057,  0.0079]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0343, -0.0221], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0328, -0.0096,  0.0326,  ...,  0.0413, -0.0175,  0.0353],\n",
      "        [-0.0026, -0.0228, -0.0229,  ..., -0.0398, -0.0426,  0.0243]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0246, -0.0396], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0438,  0.0169, -0.0408,  ...,  0.0006, -0.0065,  0.0373],\n",
      "        [ 0.0131, -0.0353,  0.0303,  ..., -0.0229,  0.0152, -0.0275]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0007, -0.0212], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "신경망을 학습할 때 가장 자주 사용되는 알고리즘은 역전파이다. 이 알고리즘에서 매ㅐㄱ변수는 주어진 매개변수에 대한 손실 함수의 gradient에 따라 조정된다\n",
    "\n",
    "이러한 gradient를 계산하기 위해 pytorch에는 torch.autograd라고 불리는 자동 미분 엔진이 내장되어 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3100, -0.4666,  3.1447], grad_fn=<AddBackward0>)\n",
      "tensor([0., 0., 0.])\n",
      "tensor(1.5113, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "print(z)\n",
    "print(y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![연산 그래프](https://tutorials.pytorch.kr/_images/comp-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Gradient 계산하기\n",
    "- 신경망에서 매개변수의 가중치를 최적화하려면 매개변수에 대한 손실함수의 도함수를 계산해야 한다\n",
    "- 도함수를 계산하기 위해 loss.backwaor() 를 호출한 다음 w.grad 와 b.grad 에서 값을 가져온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1923, 0.1285, 0.3196],\n",
      "        [0.1923, 0.1285, 0.3196],\n",
      "        [0.1923, 0.1285, 0.3196],\n",
      "        [0.1923, 0.1285, 0.3196],\n",
      "        [0.1923, 0.1285, 0.3196]])\n",
      "tensor([0.1923, 0.1285, 0.3196])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) gradient 추적 멈추기\n",
    "- 기본적으로, requires_grad=True인 모든 텐서들은 연산 기록을 추적하고 gradient 계산을 지원한다\n",
    "- 모델을 학습한 뒤 추론으로 사용하려면 (=순전파 연산만 필요한 경우) 연산 코드를 torch.no_grad() 블록으로 둘러싸서 사용해야 한다\n",
    "\n",
    "\n",
    "멈춰야 하는 이유는 다음과 같다\n",
    "- 신경망의 일부 매개변수를 고정된 매개변수로 표시\n",
    "- gradient를 추적하지 않는 텐서의 연사이 더 효율적이기 때문에, 순전파 단계만 수행할 때 연산 속도가 향상된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 결과를 얻는 다른 방법은 텐서에 detach() 메소드를 사용하는 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "모델과 데이터가 준비되었으니, 데이터에 매개변수를 최적화하여 모델을 학습하고, 검증하고, 테스트할 차례다. 모델을 학습하는 과정은 반복적인 과정을 거친다. \n",
    "\n",
    "각 반복 단계에서 모델을 출력을 추측하고, 추측과 정답 사이의 오류(loss)를 계산하고, 매개변수에 대한 ㅣoss의 도함수를 계산한 뒤 경사하강법을 사용하여 이 파라미터들을 최적화(optimize)한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 하이퍼파라미터\n",
    "\n",
    "하이퍼파라미터는 모델 최적화 과정을 제어할 수 있는 조절 가능한 매개변수이다.\n",
    "\n",
    "학습 시에는 다음과 같은 하이퍼파라미터를 정의한다\n",
    "- epoch 수 : 데이터셋을 반복하는 횟수\n",
    "- batch size : 매개변수가 갱신되기 전 신경망을 통해 전파된 데이터 샘플의 수\n",
    "- learning rate : 각 배치/에폭에서 모델의 매개변수를 조절하는 비율. 값이 작을수록 학습 속도가 느려지고, 값이 크면 원하는 최적의 값을 벗어날 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적화 단계\n",
    "하이퍼파라미터를 설정한 뒤에는 최적화 단계를 통해 모델을 학습하고 최적화할 수 있다. 최적화 단계의 각 반복(iteration)을 epoch라고 부른다\n",
    "\n",
    "하나의 에폭은 다음 두 부분으로 구성된다\n",
    "- 학습 단계 : 학습용 데이터셋을 반복하고 최적의 매개변수로 수렴\n",
    "- 검증/테스트 단계 : 모델 성능이 개선되고 있는지를 확인하기 위해 테스트 데이터셋을 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 손실 함수(loss fuction)\n",
    "- 손실 함수는 예측 결과와 실제 값 사이의 틀린 정도를 측정하여 이 정도를 최소화하려고 한다\n",
    "- 주어진 데이터 입력으로 계산한 예측과 정답을 비교하여 loss를 계산한다\n",
    "- 일반적으로 회귀 문제는 nn.MSELoss(평균 제곱 오차(MSE; Mean Square Error)) 분류에는 nn.LogSoftmax와 nn.NLLLoss를 합친 nn.CrossEntropyLoss 등이 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수를 초기화합니다.\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 옵티마이저(Optimizer)\n",
    "최적화는 각 학습 단계에서 모델의 오류를 줄이기 위해 모델 매개변수를 조정하는 과정이다. 최적화 알고리즘은 이 과정이 수행되는 방식을 정의한다.\n",
    "\n",
    "모든 최적화 절차는 optimizer 객체에 캡슐화된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 단계에서 최적화는 세단계로 이루어진다.\n",
    "- optimizer.zero_grad()를 호출하여 모델 매개변수의 변화도를 재설정한다. 기본적으로 변화도는 더해지기(add up) 때문에 중복 계산을 막기 위해 반복할 때마다 명시적으로 0으로 설정한다.\n",
    "- loss.backwards()를 호출하여 예측 손실(prediction loss)을 역전한다. PyTorch는 각 매개변수에 대한 손실의 변화도를 저장한다.\n",
    "- 변화도를 계산한 뒤에는 optimizer.step()을 호출하여 역전파 단계에서 수집된 변화도로 매개변수를 조정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 예측(prediction)과 손실(loss) 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.294617  [   64/60000]\n",
      "loss: 2.280015  [ 6464/60000]\n",
      "loss: 2.262619  [12864/60000]\n",
      "loss: 2.255829  [19264/60000]\n",
      "loss: 2.223282  [25664/60000]\n",
      "loss: 2.193916  [32064/60000]\n",
      "loss: 2.199421  [38464/60000]\n",
      "loss: 2.164192  [44864/60000]\n",
      "loss: 2.167379  [51264/60000]\n",
      "loss: 2.110047  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 2.117801 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.143735  [   64/60000]\n",
      "loss: 2.120496  [ 6464/60000]\n",
      "loss: 2.059710  [12864/60000]\n",
      "loss: 2.067012  [19264/60000]\n",
      "loss: 2.001487  [25664/60000]\n",
      "loss: 1.942121  [32064/60000]\n",
      "loss: 1.955504  [38464/60000]\n",
      "loss: 1.878235  [44864/60000]\n",
      "loss: 1.897490  [51264/60000]\n",
      "loss: 1.781241  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.9%, Avg loss: 1.804894 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 2\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장하고 불러오기\n",
    "\n",
    "pytorch 모델은 학습한 매개변수를 state_dict라고 불리는 내부 상태 사전에 저장한다. 이 상태 값들은 torch.save 메소드를 사용하여 저장할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/journey/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 가중치를 불러오기 위해서는 동일한 모델의 인스턴스를 생성한 다음에 load_state_dict() 메소드를 사용하여 매개변수들을 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16() # 여기서는 ``weights`` 를 지정하지 않았으므로, 학습되지 않은 모델을 생성합니다.\n",
    "model.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 모델의 형태를 포함하여 저장하고 불러오기\n",
    "모델 클래스의 구조를 모델과 함께 저장하고 싶으면 model을 저장 함수에 전달한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
