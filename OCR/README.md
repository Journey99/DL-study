# OCR (Optical Character Recognition) ì™„ë²½ ì •ë¦¬

## ëª©ì°¨
1. [OCR ê°œë… ë° êµ¬ì¡°](#1-ocr-ê°œë…-ë°-êµ¬ì¡°)
2. [OCR ë°œì „ ì—­ì‚¬](#2-ocr-ë°œì „-ì—­ì‚¬)
3. [ì£¼ìš” ëª¨ë¸ ë³€ì²œì‚¬](#3-ì£¼ìš”-ëª¨ë¸-ë³€ì²œì‚¬)
4. [í˜„ì¬ ë§ì´ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸](#4-í˜„ì¬-ë§ì´-ì‚¬ìš©í•˜ëŠ”-ëª¨ë¸)
5. [ë„ë©”ì¸ë³„ ëª¨ë¸ ì„ íƒ](#5-ë„ë©”ì¸ë³„-ëª¨ë¸-ì„ íƒ)
6. [ì‹¤ë¬´ ê°€ì´ë“œ](#6-ì‹¤ë¬´-ê°€ì´ë“œ)

---

## 1. OCR ê°œë… ë° êµ¬ì¡°

### 1.1 OCRì´ë€?
**Optical Character Recognition (ê´‘í•™ ë¬¸ì ì¸ì‹)**
- ì´ë¯¸ì§€ ì† í…ìŠ¤íŠ¸ë¥¼ ê¸°ê³„ê°€ ì½ì„ ìˆ˜ ìˆëŠ” ë¬¸ìë¡œ ë³€í™˜
- ìŠ¤ìº” ë¬¸ì„œ, ì‚¬ì§„, ìŠ¤í¬ë¦°ìƒ· ë“±ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

### 1.2 OCR íŒŒì´í”„ë¼ì¸

```
Input Image
    â†“
Text Detection (ì–´ë””ì— í…ìŠ¤íŠ¸ê°€ ìˆë‚˜?)
    â†“
Text Recognition (ë¬´ìŠ¨ ê¸€ìì¸ê°€?)
    â†“
Post-processing (ì–¸ì–´ ëª¨ë¸, ë³´ì •)
    â†“
Output Text
```

### 1.3 OCRì˜ ë‘ ê°€ì§€ ì£¼ìš” Task

| Task | ëª©ì  | ì¶œë ¥ | ëŒ€í‘œ ëª¨ë¸ |
|:-----|:-----|:-----|:----------|
| **Text Detection** | í…ìŠ¤íŠ¸ ì˜ì—­ ì°¾ê¸° | Bounding box/Polygon | EAST, CRAFT, DBNet |
| **Text Recognition** | í…ìŠ¤íŠ¸ ì½ê¸° | ë¬¸ìì—´ | CRNN, ASTER, ABINet |

### 1.4 OCR ë¶„ë¥˜

#### ì‘ìš© ë¶„ì•¼ë³„
- **Scene Text OCR**: ìì—° ì´ë¯¸ì§€ ì† í…ìŠ¤íŠ¸ (ê°„íŒ, í‘œì§€íŒ)
- **Document OCR**: ìŠ¤ìº” ë¬¸ì„œ, PDF (ì±…, ë…¼ë¬¸, ê³„ì•½ì„œ)
- **Handwriting Recognition**: í•„ê¸°ì²´ ì¸ì‹

#### ì²˜ë¦¬ ë°©ì‹ë³„
- **Two-Stage**: Detection â†’ Recognition (ì „í†µì )
- **End-to-End**: í•œ ë²ˆì— ì²˜ë¦¬ (ìµœì‹  íŠ¸ë Œë“œ)
- **OCR-free**: Recognition ì—†ì´ ì§ì ‘ ì´í•´ (Donut)

---

## 2. OCR ë°œì „ ì—­ì‚¬

### 2.1 ì‹œëŒ€ë³„ ë°œì „ ê³¼ì •

#### 1ì„¸ëŒ€: ê·œì¹™ ê¸°ë°˜ (1950s-1990s)
- **íŠ¹ì§•**: Template matching, íŒ¨í„´ ì¸ì‹
- **ëŒ€í‘œ**: ì´ˆê¸° Tesseract (v1-v3)
- **í•œê³„**: í°íŠ¸, í¬ê¸° ë³€í™”ì— ì·¨ì•½

#### 2ì„¸ëŒ€: ì „í†µ Machine Learning (2000s-2014)
- **íŠ¹ì§•**: Feature extraction + SVM/HMM
- **ëŒ€í‘œ**: Tesseract v3 (2007)
- **ê°œì„ **: ë‹¤ì–‘í•œ í°íŠ¸ ì²˜ë¦¬ ê°€ëŠ¥
- **í•œê³„**: Feature engineering í•„ìš”

#### 3ì„¸ëŒ€: Deep Learning ì´ˆê¸° (2014-2017)
- **íŠ¹ì§•**: CNN + RNN ì¡°í•©
- **ëŒ€í‘œ**: 
  - **CRNN** (2015): CNN + LSTM + CTC
  - **EAST** (2017): FCN ê¸°ë°˜ detection
- **í˜ì‹ **: End-to-end í•™ìŠµ, Feature ìë™ í•™ìŠµ
- **í•œê³„**: Curved text, irregular layout ì•½í•¨

#### 4ì„¸ëŒ€: Attention ì‹œëŒ€ (2017-2020)
- **íŠ¹ì§•**: Attention mechanism ë„ì…
- **ëŒ€í‘œ**:
  - **CRAFT** (2019): Character-level attention
  - **ASTER** (2018): STN + Attention
  - **SAR** (2019): 2D Attention
- **í˜ì‹ **: ë³µì¡í•œ layout, distortion ì²˜ë¦¬
- **í•œê³„**: ê¸´ í…ìŠ¤íŠ¸, context ì´í•´ ë¶€ì¡±

#### 5ì„¸ëŒ€: Transformer ì‹œëŒ€ (2020-í˜„ì¬)
- **íŠ¹ì§•**: Pure Transformer ë˜ëŠ” Hybrid
- **ëŒ€í‘œ**:
  - **TrOCR** (2021): ViT + Text Transformer
  - **ABINet** (2021): Vision + Language model
  - **PARSeq** (2022): Permutation LM
  - **Donut** (2022): OCR-free document understanding
- **í˜ì‹ **: Context ì´í•´, Pre-training í™œìš©
- **í˜„ì¬**: SOTA ì„±ëŠ¥, ë‹¤ì–‘í•œ ë„ë©”ì¸ ì ìš©

### 2.2 íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜

| ì‹œê¸° | íŒ¨ëŸ¬ë‹¤ì„ | í•µì‹¬ ê¸°ìˆ  | ì˜ˆì‹œ |
|:-----|:---------|:---------|:-----|
| ~2014 | Rule-based | Template matching | Tesseract v3 |
| 2015-2017 | CNN+RNN | CTC Loss | CRNN |
| 2018-2020 | Attention | Seq2Seq | ASTER, CRAFT |
| 2021~ | Transformer | Pre-training | TrOCR, Donut |

---

## 3. ì£¼ìš” ëª¨ë¸ ë³€ì²œì‚¬

### 3.1 Text Detection ëª¨ë¸ ë°œì „

#### EAST (2017) - ì‹¤ì‹œê°„ Detectionì˜ ì‹œì‘
- **êµ¬ì¡°**: FCN ê¸°ë°˜
- **íŠ¹ì§•**: 
  - Single-stage, fast
  - Rotated box ì§€ì›
  - Real-time ê°€ëŠ¥ (13.2ms)
- **ì˜ì˜**: Scene text detectionì˜ í‘œì¤€

#### PixelLink (2018) - Instance Segmentation ë°©ì‹
- **êµ¬ì¡°**: Pixel-level segmentation
- **íŠ¹ì§•**: 
  - Arbitrary shape text
  - Link prediction (í”½ì…€ ì—°ê²°)
- **ì˜ì˜**: Segmentation ê¸°ë°˜ ì ‘ê·¼

#### CRAFT (2019) - Character-level Detection â­
- **êµ¬ì¡°**: U-Net ê¸°ë°˜
- **íŠ¹ì§•**:
  - Character region heatmap
  - Affinity map (ê¸€ì ê°„ ì—°ê²°)
  - Weakly-supervised learning
  - Curved text ì²˜ë¦¬ ê°€ëŠ¥
- **ì˜ì˜**: í˜„ì¬ê¹Œì§€ ê°€ì¥ ë„ë¦¬ ì‚¬ìš©
- **ì„±ëŠ¥**: ICDAR15 90.0 F1-score

#### DBNet/DBNet++ (2020/2022) - Differentiable Binarization
- **êµ¬ì¡°**: ResNet + FPN
- **íŠ¹ì§•**:
  - Differentiable binarization
  - Adaptive threshold
  - Real-time + High accuracy
- **ì˜ì˜**: PaddleOCRì˜ ê¸°ë³¸ detector
- **ì„±ëŠ¥**: ICDAR15 91.5 F1-score

### 3.2 Text Recognition ëª¨ë¸ ë°œì „

#### CRNN (2015) - Recognitionì˜ ê¸°ì´ˆ â­
```
CNN (Feature extraction)
  â†“
RNN/LSTM (Sequence modeling)
  â†“
CTC (Decoding)
```
- **ì˜ì˜**: OCR recognitionì˜ í‘œì¤€ êµ¬ì¡°
- **ì¥ì **: End-to-end, ê°€ë³€ ê¸¸ì´ ì²˜ë¦¬
- **í•œê³„**: Context ì •ë³´ ë¶€ì¡±

#### Attention-based (2016-2018) - Seq2Seq ë„ì…
- **Show, Attend and Read** (2016)
- **êµ¬ì¡°**: Encoder-Decoder + Attention
- **íŠ¹ì§•**: CTC ì—†ì´ ì§ì ‘ ë¬¸ì ì˜ˆì¸¡
- **ì¥ì **: Alignment ìë™ í•™ìŠµ

#### ASTER (2018) - Rectification ë„ì…
```
STN (Spatial Transformer Network)
  â†“ (ì´ë¯¸ì§€ rectify)
Recognition Network (Attention-based)
```
- **í˜ì‹ **: Curved/distorted text ì²˜ë¦¬
- **ì„±ëŠ¥**: Irregular textì—ì„œ ìš°ìˆ˜

#### SAR (2019) - 2D Attention
- **êµ¬ì¡°**: 2D attention mechanism
- **íŠ¹ì§•**: 
  - Spatial ì •ë³´ ë” ì˜ í™œìš©
  - Irregular text ê°•í•¨

#### ABINet (2021) - Language Model í†µí•© â­
```
Vision Model (BiLSTM)
  â†“
Language Model (Transformer)
  â†“
Fusion (Iterative correction)
```
- **í˜ì‹ **: Vision + Language í†µí•©
- **íŠ¹ì§•**:
  - Occluded text ë³µì›
  - Context ì´í•´
  - Iterative refinement
- **ì„±ëŠ¥**: ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ SOTA

#### PARSeq (2022) - Permutation Language Model
- **êµ¬ì¡°**: Transformer encoder-decoder
- **íŠ¹ì§•**:
  - Permutation language modeling
  - Context-aware prediction
  - Single model for multiple tasks
- **ì„±ëŠ¥**: 7ê°œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ SOTA

#### SVTR (2022) - Simple ViT
- **êµ¬ì¡°**: Vision Transformer ê¸°ë°˜
- **íŠ¹ì§•**:
  - ë‹¨ìˆœí•˜ê³  íš¨ê³¼ì 
  - Multi-scale features
- **ì„±ëŠ¥**: ë¹ ë¥´ë©´ì„œ ì •í™•

### 3.3 End-to-End ëª¨ë¸ ë°œì „

#### Mask TextSpotter (2018/v3 2020)
- **êµ¬ì¡°**: Mask R-CNN ê¸°ë°˜
- **íŠ¹ì§•**: Detection + Recognition ë™ì‹œ
- **ë°©ì‹**: Instance segmentation

#### ABCNet (2020) / ABCNetv2 (2021)
- **êµ¬ì¡°**: Bezier curve representation
- **íŠ¹ì§•**:
  - Arbitrary shape text
  - Real-time capable
  - End-to-end differentiable

#### TESTR (2022) - Transformer Spotting
- **êµ¬ì¡°**: DETR ë°©ì‹
- **íŠ¹ì§•**:
  - Query-based
  - Transformer end-to-end
  - No NMS

### 3.4 Document OCR ì „ë¬¸ ëª¨ë¸

#### Tesseract (1985-í˜„ì¬)
- **ë°œì „**:
  - v3 (2007): Traditional ML
  - v4 (2018): LSTM ë„ì…
  - v5 (2021): ë‹¤êµ­ì–´ ê°œì„ 
- **íŠ¹ì§•**: 
  - ì˜¤í”ˆì†ŒìŠ¤ í‘œì¤€
  - 100+ ì–¸ì–´ ì§€ì›
  - ë¬¸ì„œ OCRì— ìµœì í™”

#### LayoutLM ì‹œë¦¬ì¦ˆ (2020-2022, Microsoft)
- **LayoutLM** (2020): BERT + Layout
- **LayoutLMv2** (2021): Visual features ì¶”ê°€
- **LayoutLMv3** (2022): Unified architecture
- **íŠ¹ì§•**:
  - Document understanding
  - Layout ì •ë³´ í™œìš©
  - Form, Invoice, Receipt ì²˜ë¦¬

#### TrOCR (2021, Microsoft) - Transformer OCR â­
```
Vision Encoder (ViT/DeiT)
  â†“
Text Decoder (RoBERTa)
```
- **íŠ¹ì§•**:
  - Pre-trained ViT + Language model
  - End-to-end Transformer
  - Handwriting ìš°ìˆ˜
- **ì¥ì **: Fine-tuning ì‰¬ì›€, HuggingFace ì§€ì›

#### Donut (2022) - OCR-free â­
- **í˜ì‹ **: OCR ì—†ì´ ì§ì ‘ ë¬¸ì„œ ì´í•´
- **êµ¬ì¡°**: Swin Transformer + BART
- **íŠ¹ì§•**:
  - Document classification
  - Information extraction
  - VQA (Visual Question Answering)
- **ì¥ì **: OCR ì—ëŸ¬ ì „íŒŒ ì—†ìŒ

#### Nougat (2023, Meta)
- **ëª©ì **: Scientific PDF â†’ Markdown
- **íŠ¹ì§•**:
  - LaTeX ìˆ˜ì‹ ì²˜ë¦¬
  - Table, Figure ì´í•´
  - í•™ìˆ  ë…¼ë¬¸ íŠ¹í™”

---

## 4. í˜„ì¬ ë§ì´ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸

### 4.1 ì‹¤ë¬´ ì‚¬ìš© ë¹ˆë„ Top 5

#### ğŸ¥‡ 1ìœ„: EasyOCR
```python
import easyocr
reader = easyocr.Reader(['ko', 'en'])
results = reader.readtext('image.jpg')
```

**ì‚¬ìš©ë¥ :** â­â­â­â­â­

**ì¥ì :**
- ì„¤ì¹˜ ë° ì‚¬ìš© ë§¤ìš° ê°„ë‹¨
- 80+ ì–¸ì–´ ì§€ì›
- Detection (CRAFT) + Recognition í†µí•©
- GPU ê°€ì† ì§€ì›
- í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°

**ë‹¨ì :**
- ì»¤ìŠ¤í„°ë§ˆì´ì§• ì œí•œì 
- ì†ë„ ìµœì í™” ì—¬ì§€

**ì‚¬ìš© ì‚¬ë¡€:**
- í”„ë¡œí† íƒ€ì… ê°œë°œ
- ë‹¤êµ­ì–´ OCR
- Scene text reading

---

#### ğŸ¥ˆ 2ìœ„: PaddleOCR
```python
from paddleocr import PaddleOCR
ocr = PaddleOCR(lang='korean')
result = ocr.ocr('image.jpg')
```

**ì‚¬ìš©ë¥ :** â­â­â­â­â­

**ì¥ì :**
- ë§¤ìš° ë¹ ë¥¸ ì†ë„ (ìµœì í™” ìš°ìˆ˜)
- ë†’ì€ ì •í™•ë„
- PP-OCR, PP-OCRv2, PP-OCRv3 ì‹œë¦¬ì¦ˆ
- ëª¨ë°”ì¼ ë°°í¬ ì§€ì›
- ì‚°ì—…ê³„ í‘œì¤€

**ë‹¨ì :**
- ì¤‘êµ­ì–´ ë¬¸ì„œê°€ ë§ìŒ
- PaddlePaddle í”„ë ˆì„ì›Œí¬ ì˜ì¡´

**ì‚¬ìš© ì‚¬ë¡€:**
- í”„ë¡œë•ì…˜ ë°°í¬
- ëª¨ë°”ì¼ ì•±
- ì‹¤ì‹œê°„ ì²˜ë¦¬

---

#### ğŸ¥‰ 3ìœ„: Tesseract
```python
import pytesseract
from PIL import Image

text = pytesseract.image_to_string(Image.open('image.jpg'), lang='kor+eng')
```

**ì‚¬ìš©ë¥ :** â­â­â­â­

**ì¥ì :**
- ì˜¤í”ˆì†ŒìŠ¤ ì›ì¡°
- 100+ ì–¸ì–´ ì§€ì›
- ë¬¸ì„œ OCRì— ê°•í•¨
- PDF ì²˜ë¦¬ ê°€ëŠ¥
- ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥ (í•™ìŠµ ê°€ëŠ¥)

**ë‹¨ì :**
- Scene text ì•½í•¨
- ì „ì²˜ë¦¬ í•„ìˆ˜
- ì†ë„ ëŠë¦¼

**ì‚¬ìš© ì‚¬ë¡€:**
- ë¬¸ì„œ ë””ì§€íƒ€ì´ì œì´ì…˜
- PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
- ì±…/ë…¼ë¬¸ ìŠ¤ìº”

---

#### 4ìœ„: TrOCR (Hugging Face)
```python
from transformers import TrOCRProcessor, VisionEncoderDecoderModel

processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-printed')
model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-printed')

pixel_values = processor(images=image, return_tensors="pt").pixel_values
generated_ids = model.generate(pixel_values)
text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
```

**ì‚¬ìš©ë¥ :** â­â­â­â­

**ì¥ì :**
- Transformer ê¸°ë°˜ SOTA
- Handwriting ìš°ìˆ˜
- Fine-tuning ì‰¬ì›€
- Pre-trained ëª¨ë¸ í’ë¶€
- HuggingFace ìƒíƒœê³„

**ë‹¨ì :**
- Recognition only (Detection ë³„ë„)
- GPU í•„ìˆ˜
- ì¶”ë¡  ì†ë„ ëŠë¦¼

**ì‚¬ìš© ì‚¬ë¡€:**
- í•„ê¸°ì²´ ì¸ì‹
- ê³ í’ˆì§ˆ document OCR
- ì—°êµ¬ ë° ì‹¤í—˜

---

#### 5ìœ„: MMOCR
```python
from mmocr.apis import MMOCRInferencer

ocr = MMOCRInferencer(det='DBNet', rec='ABINet')
result = ocr('image.jpg')
```

**ì‚¬ìš©ë¥ :** â­â­â­

**ì¥ì :**
- ê±°ì˜ ëª¨ë“  OCR ëª¨ë¸ êµ¬í˜„
- Config ê¸°ë°˜ ì‹¤í—˜
- ì—°êµ¬ìš© ìµœì 
- OpenMMLab ìƒíƒœê³„

**ë‹¨ì :**
- ì„¤ì • ë³µì¡
- ì‹¤ë¬´ ë°°í¬ ì–´ë ¤ì›€
- í•™ìŠµ ê³¡ì„  ë†’ìŒ

**ì‚¬ìš© ì‚¬ë¡€:**
- OCR ì—°êµ¬
- ëª¨ë¸ ë¹„êµ ì‹¤í—˜
- SOTA ëª¨ë¸ í…ŒìŠ¤íŠ¸

---

### 4.2 ë„ë©”ì¸ë³„ ìµœê³  ëª¨ë¸

| ë„ë©”ì¸ | ì¶”ì²œ ëª¨ë¸ | ì´ìœ  |
|:-------|:---------|:-----|
| **Scene Text** | EasyOCR, PaddleOCR | ë²”ìš©ì„±, ì •í™•ë„ |
| **Document** | Tesseract, TrOCR | ë¬¸ì„œ íŠ¹í™” |
| **Handwriting** | TrOCR, IAM-based models | Transformer ìš°ìˆ˜ |
| **Form/Invoice** | LayoutLMv3, Donut | Layout ì´í•´ |
| **Scientific PDF** | Nougat | LaTeX, ìˆ˜ì‹ ì²˜ë¦¬ |
| **Real-time** | PaddleOCR-mobile | ì†ë„ ìµœì í™” |
| **ë‹¤êµ­ì–´** | EasyOCR | 80+ ì–¸ì–´ |

### 4.3 ì–¸ì–´ë³„ ì¶”ì²œ

#### í•œêµ­ì–´
1. **EasyOCR** - ë²”ìš©ì„±
2. **PaddleOCR** - ì†ë„
3. **Naver Clova OCR** - ìƒìš© (ê°€ì¥ ì •í™•)
4. **Pororo** - í•œêµ­ì–´ NLP í†µí•©

#### ì˜ì–´
1. **TrOCR** - SOTA
2. **Tesseract** - ë¬¸ì„œ
3. **PaddleOCR** - ì‹¤ì‹œê°„

#### ì¤‘êµ­ì–´
1. **PaddleOCR** - ì¤‘êµ­ Baidu
2. **ChineseOCR** - íŠ¹í™”
3. **MMOCR** - ì—°êµ¬

#### ì¼ë³¸ì–´
1. **manga-ocr** - ë§Œí™”
2. **PaddleOCR** - ë²”ìš©
3. **EasyOCR** - ê°„ë‹¨

---

## 5. ë„ë©”ì¸ë³„ ëª¨ë¸ ì„ íƒ

### 5.1 Scene Text OCR

**íŠ¹ì§•:**
- ìì—° ì´ë¯¸ì§€ ì† í…ìŠ¤íŠ¸
- ë‹¤ì–‘í•œ í°íŠ¸, í¬ê¸°, ê°ë„
- ì¡°ëª…, ê·¸ë¦¼ì, ì™œê³¡

**ìµœì  ì¡°í•©:**
```
Detection: CRAFT or DBNet
Recognition: ABINet or PARSeq
Framework: EasyOCR or PaddleOCR
```

**ì‚¬ìš© ì‚¬ë¡€:**
- ê°„íŒ, í‘œì§€íŒ ì¸ì‹
- AR ë²ˆì—­
- ììœ¨ì£¼í–‰ (êµí†µí‘œì§€)

### 5.2 Document OCR

**íŠ¹ì§•:**
- ìŠ¤ìº” ë¬¸ì„œ, PDF
- ì •í˜•í™”ëœ ë ˆì´ì•„ì›ƒ
- ë†’ì€ í•´ìƒë„

**ìµœì  ëª¨ë¸:**
```
ì¼ë°˜ ë¬¸ì„œ: Tesseract, TrOCR
Form/Invoice: LayoutLMv3, Donut
í•™ìˆ  ë…¼ë¬¸: Nougat
```

**ì‚¬ìš© ì‚¬ë¡€:**
- ê³„ì•½ì„œ ë””ì§€íƒ€ì´ì œì´ì…˜
- ì²­êµ¬ì„œ ìë™í™”
- ë…¼ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ

### 5.3 Handwriting Recognition

**íŠ¹ì§•:**
- í•„ê¸°ì²´ ë‹¤ì–‘ì„±
- ë‚®ì€ í’ˆì§ˆ
- Context ì¤‘ìš”

**ìµœì  ëª¨ë¸:**
```
ì¸ì‡„ëœ ì†ê¸€ì”¨: TrOCR (trocr-base-handwritten)
ììœ ë¡œìš´ í•„ê¸°: IAM-based CRNN
ì—­ì‚¬ì  ë¬¸ì„œ: Transkribus
```

**ì‚¬ìš© ì‚¬ë¡€:**
- ì„¤ë¬¸ì¡°ì‚¬ ë””ì§€íƒ€ì´ì œì´ì…˜
- ì—­ì‚¬ ë¬¸ì„œ ë³´ì¡´
- ì†í¸ì§€ ë””ì§€í„¸í™”

### 5.4 Real-time OCR

**íŠ¹ì§•:**
- ëª¨ë°”ì¼/ì—£ì§€ ë””ë°”ì´ìŠ¤
- ì œí•œëœ ë¦¬ì†ŒìŠ¤
- ë¹ ë¥¸ ì‘ë‹µ í•„ìš”

**ìµœì  ëª¨ë¸:**
```
Mobile: PaddleOCR-mobile (PP-OCRv3)
Edge: DBNet-MobileNetV3 + CRNN-tiny
Web: EasyOCR (lightweight mode)
```

**ì‚¬ìš© ì‚¬ë¡€:**
- ëª¨ë°”ì¼ ìŠ¤ìºë„ˆ ì•±
- ì‹¤ì‹œê°„ ë²ˆì—­
- POS ì‹œìŠ¤í…œ

---

## 6. ì‹¤ë¬´ ê°€ì´ë“œ

### 6.1 ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

#### ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
```python
# ê°€ì¥ ê°„ë‹¨ - EasyOCR
import easyocr
reader = easyocr.Reader(['ko', 'en'])
result = reader.readtext('image.jpg')
print(result)
```

#### ê³ ì •í™•ë„ í•„ìš”
```python
# PaddleOCR
from paddleocr import PaddleOCR
ocr = PaddleOCR(use_angle_cls=True, lang='korean')
result = ocr.ocr('image.jpg', cls=True)
```

#### ë¬¸ì„œ ì²˜ë¦¬
```python
# Tesseract
import pytesseract
from PIL import Image
text = pytesseract.image_to_string(Image.open('doc.jpg'), lang='kor+eng')
```

#### í•„ê¸°ì²´ ì¸ì‹
```python
# TrOCR
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')
model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')
```

### 6.2 ì„±ëŠ¥ ìµœì í™” íŒ

#### ì „ì²˜ë¦¬
```python
import cv2

# 1. Grayscale ë³€í™˜
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# 2. Noise ì œê±°
denoised = cv2.fastNlMeansDenoising(gray)

# 3. Binarization
_, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

# 4. Deskew (ê¸°ìš¸ê¸° ë³´ì •)
# ... skew detection and correction
```

#### í›„ì²˜ë¦¬
```python
# 1. ì–¸ì–´ ëª¨ë¸ ì ìš©
from symspellpy import SymSpell
sym_spell = SymSpell()
corrected = sym_spell.lookup(text, Verbosity.CLOSEST)

# 2. ì •ê·œ í‘œí˜„ì‹ ì •ì œ
import re
text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', text)

# 3. Confidence filtering
results = [r for r in results if r['confidence'] > 0.5]
```

### 6.3 ëª¨ë¸ ì„ íƒ Decision Tree

```
ëª©ì ì´ ë¬´ì—‡ì¸ê°€?
â”œâ”€ Scene Text (ìì—° ì´ë¯¸ì§€)
â”‚  â”œâ”€ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… â†’ EasyOCR
â”‚  â”œâ”€ í”„ë¡œë•ì…˜ ë°°í¬ â†’ PaddleOCR
â”‚  â””â”€ ìµœê³  ì •í™•ë„ â†’ CRAFT + ABINet (MMOCR)
â”‚
â”œâ”€ Document (ë¬¸ì„œ)
â”‚  â”œâ”€ ì¼ë°˜ ë¬¸ì„œ â†’ Tesseract or TrOCR
â”‚  â”œâ”€ Form/Invoice â†’ LayoutLMv3 or Donut
â”‚  â””â”€ í•™ìˆ  ë…¼ë¬¸ â†’ Nougat
â”‚
â”œâ”€ Handwriting (í•„ê¸°ì²´)
â”‚  â”œâ”€ ì¸ì‡„ëœ ì†ê¸€ì”¨ â†’ TrOCR (printed)
â”‚  â””â”€ ììœ  í•„ê¸° â†’ TrOCR (handwritten)
â”‚
â””â”€ Real-time (ì‹¤ì‹œê°„)
   â”œâ”€ Mobile â†’ PaddleOCR-mobile
   â””â”€ Web â†’ EasyOCR (lightweight)
```

### 6.4 í‰ê°€ ì§€í‘œ

| ì§€í‘œ | ì„¤ëª… | ì‚¬ìš©ì²˜ |
|:-----|:-----|:-------|
| **Precision** | ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ë§ì¶˜ ë¹„ìœ¨ | Detection |
| **Recall** | ì‹¤ì œ ì¤‘ ì°¾ì€ ë¹„ìœ¨ | Detection |
| **F1-score** | Precisionê³¼ Recall ì¡°í™”í‰ê·  | Detection |
| **CER** | Character Error Rate | Recognition |
| **WER** | Word Error Rate | Recognition |
| **Accuracy** | ì •í™•íˆ ë§ì¶˜ ë¹„ìœ¨ | Recognition |
| **1-NED** | Normalized Edit Distance | Recognition |

### 6.5 Common Issues & Solutions

| ë¬¸ì œ | ì›ì¸ | í•´ê²°ì±… |
|:-----|:-----|:-------|
| ë‚®ì€ ì •í™•ë„ | ì´ë¯¸ì§€ í’ˆì§ˆ | ì „ì²˜ë¦¬ ê°•í™”, í•´ìƒë„ í–¥ìƒ |
| ëŠë¦° ì†ë„ | ëª¨ë¸ í¬ê¸° | ê²½ëŸ‰ ëª¨ë¸, ë°°ì¹˜ ì²˜ë¦¬ |
| íŠ¹ìˆ˜ ë¬¸ì ì˜¤ë¥˜ | í•™ìŠµ ë°ì´í„° ë¶€ì¡± | Fine-tuning, í›„ì²˜ë¦¬ |
| Layout ì˜¤ë¥˜ | Detection ì‹¤íŒ¨ | Detection ëª¨ë¸ ê°œì„  |
| ë‹¤êµ­ì–´ í˜¼ì¬ | ë‹¨ì¼ ì–¸ì–´ ëª¨ë¸ | ë‹¤êµ­ì–´ ëª¨ë¸, ì–¸ì–´ ê°ì§€ |

### 6.6 ë°°í¬ ê³ ë ¤ì‚¬í•­

#### On-premise
- **ëª¨ë¸**: PaddleOCR, Tesseract
- **ì¥ì **: ë°ì´í„° ë³´ì•ˆ
- **ë‹¨ì **: ì¸í”„ë¼ ê´€ë¦¬

#### Cloud API
- **ì„œë¹„ìŠ¤**: Google Vision API, AWS Textract, Naver Clova
- **ì¥ì **: ê´€ë¦¬ ë¶ˆí•„ìš”, ë†’ì€ ì •í™•ë„
- **ë‹¨ì **: ë¹„ìš©, ì¸í„°ë„· ì˜ì¡´

#### Edge/Mobile
- **ëª¨ë¸**: PaddleOCR-mobile, CRNN-tiny
- **ì¥ì **: ì˜¤í”„ë¼ì¸ ê°€ëŠ¥, ë¹ ë¦„
- **ë‹¨ì **: ì •í™•ë„ trade-off

---

## 7. ì°¸ê³  ìë£Œ

### ì£¼ìš” ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹
- **ICDAR**: Scene text (2013, 2015, 2017, 2019)
- **COCO-Text**: Natural images
- **SVT**: Street View Text
- **IIIT5K**: Scene text
- **IAM**: Handwriting
- **SROIE**: Receipt OCR
- **RVL-CDIP**: Document classification

### ìœ ìš©í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **EasyOCR**: https://github.com/JaidedAI/EasyOCR
- **PaddleOCR**: https://github.com/PaddlePaddle/PaddleOCR
- **MMOCR**: https://github.com/open-mmlab/mmocr
- **Tesseract**: https://github.com/tesseract-ocr/tesseract
- **TrOCR**: https://huggingface.co/docs/transformers/model_doc/trocr

### ì—°êµ¬ ë¦¬ì†ŒìŠ¤
- **Papers with Code - OCR**: https://paperswithcode.com/task/optical-character-recognition
- **Awesome OCR**: https://github.com/kba/awesome-ocr
- **OCR Datasets**: https://github.com/cs-chan/Total-Text-Dataset

---

## 8. ìš”ì•½

### í•µì‹¬ í¬ì¸íŠ¸
1. **OCR = Detection + Recognition** ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±
2. **ì‹œëŒ€ë³„ ë°œì „**: Rule-based â†’ ML â†’ DL â†’ Attention â†’ Transformer
3. **ì‹¤ë¬´ Top 3**: EasyOCR, PaddleOCR, Tesseract
4. **ìµœì‹  SOTA**: TrOCR, ABINet, PARSeq, Donut
5. **ë„ë©”ì¸ë³„ íŠ¹í™”**: Scene/Document/Handwriting ê°ê° ìµœì  ëª¨ë¸ ì¡´ì¬